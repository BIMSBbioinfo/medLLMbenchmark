{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import boto3\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_display(data):\n",
    "    # Display the DataFrame with scroll and define the height and width for the scrollable area\n",
    "    display(HTML(f'''\n",
    "    <div style=\"height: 500px; overflow-y: scroll; overflow-x: scroll; border: 1px solid black; padding: 5px;\">\n",
    "        {data.to_html(max_rows=None, max_cols=None)}\n",
    "    </div>\n",
    "    '''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data from postprocessing.ipynb\n",
    "df = pd.read_csv(\"MIMIC-IV-Ext-Diagnosis-prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: LLM evaluates the diagnosis predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to evaluate the diagnosis predictions with retry logic\n",
    "def get_evaluation_diagnosis(row, key, chain, max_retries=5, initial_wait=1):\n",
    "    diagnosis = row[\"primary_diagnosis\"]\n",
    "    diag1 = row[key][0]\n",
    "    diag2 = row[key][1]\n",
    "    diag3 = row[key][2]\n",
    "\n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            # Invoke the chain with the diagnosis and icd_code\n",
    "            evaluation= chain.invoke({\"real_diag\": diagnosis, \"diag1\": diag1, \"diag2\": diag2, \"diag3\": diag3}).content\n",
    "            #print(evaluation)\n",
    "            return evaluation  # Return on successful invocation\n",
    "\n",
    "        except Exception as e:\n",
    "            # Check if the error is a ThrottlingException or similar\n",
    "            if \"ThrottlingException\" in str(e) or \"Too many requests\" in str(e):\n",
    "                # Exponential backoff\n",
    "                wait_time = initial_wait * (2 ** attempt)\n",
    "                print(f\"Throttling detected. Retrying after {wait_time} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "                attempt += 1\n",
    "            else:\n",
    "                # Handle other types of exceptions\n",
    "                return f\"Error: {str(e)}\"\n",
    "    # If all retries fail, return an error\n",
    "    return \"Error: Max retries exceeded\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the diagnosis rows into lists - data in columns are stored as strings but actually represent lists\n",
    "df['diagnosis_Claude3.5'] = df['diagnosis_Claude3.5'].apply(lambda x: eval(x))\n",
    "df['diagnosis_Claude3'] = df['diagnosis_Claude3'].apply(lambda x: eval(x))\n",
    "df['diagnosis_Haiku'] = df['diagnosis_Haiku'].apply(lambda x: eval(x))\n",
    "df['diagnosis_Claude3.5_Clincal'] = df['diagnosis_Claude3.5_Clincal'].apply(lambda x: eval(x))\n",
    "df['diagnosis_Claude3_Clinical'] = df['diagnosis_Claude3_Clincal'].apply(lambda x: eval(x))\n",
    "df['diagnosis_Haiku_Clinical'] = df['diagnosis_Haiku_Clinical'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the prompt template\n",
    "prompt = \"\"\"You are an experienced healthcare professional with expertise in medical and clinical domains. I will provide a list of real diagnoses for a patient and 3 predicted diagnoses. For each predicted diagnosis, determine if it has the same meaning as one of the real diagnoses or if the prediction falls under a broader category of one of the real diagnoses (e.g., a specific condition falling under a general diagnosis category). If it matches, return 'True'; otherwise, return 'False'. Return only 'True' or 'False' for each predicted diagnosis within <evaluation> tags and nothing else.\n",
    "Real Diagnoses: {real_diag}, predicted diagnosis 1: {diag1}, predicted diagnosis 2: {diag2}, and predicted diagnosis 3: {diag3}.\"\"\"\n",
    "\n",
    "\n",
    "## set AWS credentials\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]=\"Enter your AWS Access Key ID\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]=\"Enter your AWS Secret Access Key\"\n",
    "\n",
    "prompt_chain = PromptTemplate(template=prompt,input_variables=[\"real_diag\", \"diag1\", \"diag2\", \"diag3\"])\n",
    "client = boto3.client(service_name=\"bedrock-runtime\", region_name=str(\"us-east-1\"))\n",
    "\n",
    "\n",
    "## Claude Sonnet 3.5\n",
    "llm_claude35 = ChatBedrock(model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\", model_kwargs={\"temperature\": 0}, client=client)\n",
    "chain_claude35 = prompt_chain | llm_claude35\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "keys = [\"diagnosis_Claude3.5\", \"diagnosis_Claude3\", 'diagnosis_Haiku', 'diagnosis_Claude3.5_Clinical', 'diagnosis_Claude3_Clinical','diagnosis_Haiku_Clinical']\n",
    "\n",
    "for key in keys:\n",
    "    df[\"eval_\"+key] = df.progress_apply(lambda row: get_evaluation_diagnosis(row, key, chain_claude35), axis=1)\n",
    "    df.to_csv('MIMIC-IV-Ext-Diagnosis-evaluation.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envphd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
