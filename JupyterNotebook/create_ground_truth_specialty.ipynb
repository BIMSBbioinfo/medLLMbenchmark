{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import boto3\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_display(data):\n",
    "    # Display the DataFrame with scroll and define the height and width for the scrollable area\n",
    "    display(HTML(f'''\n",
    "    <div style=\"height: 500px; overflow-y: scroll; overflow-x: scroll; border: 1px solid black; padding: 5px;\">\n",
    "        {data.to_html(max_rows=None, max_cols=None)}\n",
    "    </div>\n",
    "    '''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE GROUND TRUTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM create ground truth for the specialty prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth_specialty(row, chain, max_retries=5, initial_wait=1):\n",
    "    diagnosis = row[\"primary_diagnosis\"]\n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            # Invoke the chain with the diagnosis and icd_code\n",
    "\n",
    "            specialty = chain.invoke({\"diagnosis\": diagnosis}).content\n",
    "            return specialty  # Return on successful invocation\n",
    "\n",
    "        except Exception as e:\n",
    "            # Check if the error is a ThrottlingException or similar\n",
    "            if \"ThrottlingException\" in str(e) or \"Too many requests\" in str(e):\n",
    "                # Exponential backoff\n",
    "                wait_time = initial_wait * (2 ** attempt)\n",
    "                print(f\"Throttling detected. Retrying after {wait_time} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "                attempt += 1\n",
    "            else:\n",
    "                # Handle other types of exceptions\n",
    "                return f\"Error: {str(e)}\"\n",
    "    # If all retries fail, return an error\n",
    "    return \"Error: Max retries exceeded\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data from MIMIC-IV-Ext-Creation.ipynb\n",
    "df = pd.read_csv('MIMIC-IV-Ext-Triage-Specialty-Diagnosis-Decision-Support.csv')\n",
    "\n",
    "## Convert the diagnosis rows into lists - data in columns are stored as strings but actually represent lists\n",
    "df['primary_diagnosis'] = df['primary_diagnosis'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract unique diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten all diagnoses\n",
    "diagnoses = [diagnosis for sublist in df['primary_diagnosis'] for diagnosis in sublist]\n",
    "\n",
    "unique_diagnosis = set(diagnoses)\n",
    "unique_diagnosis = pd.DataFrame(unique_diagnosis, columns=['primary_diagnosis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM create ground truth specialty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template\n",
    "prompt = \"\"\"You are an experienced healthcare professional with expertise in medical and clinical domains. Determine the medical specialty most appropriate for the patient to consult based on the diagnosis. Please analyze the given diagnosis and predict the medical specialty that would typically manage the condition associated with it. If the condition might be treated by multiple specialties, prioritize the one most likely to manage the majority of cases. Respond with the specialty name only. Give the specialty in a <specialty> tag. If you can't find a specialty return 'no answer' in a <specialty> tag.\n",
    "Diagnosis: {diagnosis}.\"\"\"\n",
    "\n",
    "## set AWS credentials\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]=\"Enter your AWS Access Key ID\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]=\"Enter your AWS Secret Access Key\"\n",
    "\n",
    "prompt_chain = PromptTemplate(template=prompt,input_variables=[\"diagnosis\"])\n",
    "client = boto3.client(service_name=\"bedrock-runtime\", region_name=str(\"us-east-1\"))\n",
    "\n",
    "## Claude Sonnet 3.5\n",
    "llm_claude35 = ChatBedrock(model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\", model_kwargs={\"temperature\": 0}, client=client)\n",
    "chain_claude35 = prompt_chain | llm_claude35\n",
    "\n",
    "## Run LLM to retrieve ground truth specialties \n",
    "tqdm.pandas()\n",
    "unique_diagnosis[\"specialty_primary_diagnosis\"] = unique_diagnosis.progress_apply(lambda row: get_ground_truth_specialty(row, chain_claude35), axis=1)\n",
    "\n",
    "unique_diagnosis.to_csv('df_specialty_groundtruth.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge ground truth specialty to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parsing\n",
    "def parse_response(specialty):\n",
    "    #parse whats in between <specialty>  and </specialty> tag\n",
    "    specialty = specialty.split('<specialty>')[-1].split('</specialty>')[0]\n",
    "    return specialty\n",
    "\n",
    "unique_diagnosis[\"specialty_primary_diagnosis\"] = unique_diagnosis[\"specialty_primary_diagnosis\"].apply(parse_response)\n",
    "\n",
    "## Create a dictionary for fast lookup of specialties\n",
    "diagnosis_to_specialty = pd.Series(unique_diagnosis.specialty_primary_diagnosis.values, index=unique_diagnosis.primary_diagnosis).to_dict()\n",
    "\n",
    "\n",
    "## Function to map diagnosis list to a list of specialties\n",
    "def get_specialties(diagnosis_list_column, specialty_look_up_dict):\n",
    "\n",
    "    specialty_primary_diagnosis = diagnosis_list_column.apply(lambda diagnosis_list: [specialty_look_up_dict.get(diagnosis, 'Unknown Specialty') for diagnosis in diagnosis_list])\n",
    "    \n",
    "    return specialty_primary_diagnosis\n",
    "\n",
    "## assign each diagnosis in the list of diagnoses of each row a specialty as a ground truth\n",
    "df['specialty_primary_diagnosis'] = get_specialties(df[\"primary_diagnosis\"], diagnosis_to_specialty)\n",
    "\n",
    "## save files (triage, diag, spec)\n",
    "df.to_csv('df_mimic_iv_ext_triage_diag_spec.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Dataset for each modality (Specialty and Diagnosis, Triage)\n",
    "df_diag_spec = df.copy()\n",
    "df_triage = df.copy()\n",
    "\n",
    "\n",
    "## Cleaning the Dataframe for clarity\n",
    "df_diag_spec  = df_diag_spec.drop(columns=[\"subject_id\", \"hadm_id\", \"pain\", \"chiefcomplaint\", \"tests\", \"triage\", \"icd_code\", \"icd_title\", \"icd_version\"], inplace=False)\n",
    "df_triage  = df_triage.drop(columns=[\"subject_id\", \"hadm_id\", \"pain\", \"chiefcomplaint\", \"tests\", \"icd_code\", \"icd_title\", \"icd_version\", \"diagnosis\", \"primary_diagnosis\", \"secondary_diagnosis\", \"specialty_primary_diagnosis\"], inplace=False)\n",
    "\n",
    "\n",
    "## save files\n",
    "df_diag_spec.to_csv('MIMIC-IV-Ext-Diagnosis-Specialty.csv', index=False)\n",
    "df_triage.to_csv('MIMIC-IV-Ext-Triage.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE DATASET FOR EACH MODALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"testrun_df_mimic_iv_ext_triage_diag_spec.csv\")\n",
    "df_diag_spec = df.copy()\n",
    "df_acuity = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diag_spec  = df_diag_spec.drop(columns=[\"subject_id\", \"hadm_id\", \"pain\", \"chiefcomplaint\", \"tests\", \"acuity\", \"icd_code\", \"icd_title\", \"icd_version\"], inplace=False)\n",
    "df_acuity  = df_acuity.drop(columns=[\"subject_id\", \"hadm_id\", \"pain\", \"chiefcomplaint\", \"tests\", \"icd_code\", \"icd_title\", \"icd_version\", \"diagnosis\", \"primary_diagnosis\", \"secondary_diagnosis\", \"specialty_primary_diagnosis\"], inplace=False)\n",
    "\n",
    "df_diag_spec.to_csv('testrun_df_mimic_iv_ext_diag_spec.csv', index=False)\n",
    "df_acuity.to_csv('testrun_df_mimic_iv_ext_acuity.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envphd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
